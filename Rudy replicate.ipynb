{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from distributions import Categorical, DiagGaussian\n",
    "from utils import orthogonal\n",
    "\n",
    "from all_stuff import *\n",
    "\n",
    "from envs import make_env # had to manually add some files into directory for env to reference bc baselines \n",
    "# modules not working right\n",
    "\n",
    "#from storage import RolloutStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.env_name='PongNoFrameskip-v4'\n",
    "        self.seed=1\n",
    "        self.log_dir=''\n",
    "        self.save_dir='saved_models'\n",
    "        self.cuda=False\n",
    "        self.algo='a2c'\n",
    "        self.num_stack=4\n",
    "        self.num_steps=5\n",
    "        self.num_processes=16\n",
    "        self.lr=7e-4\n",
    "        self.eps=1e-5\n",
    "        self.alpha=.99\n",
    "        self.max_grad_norm=.5\n",
    "        self.value_loss_coef=.5\n",
    "        self.entropy_coef=.1\n",
    "        self.num_frames=8e6\n",
    "        self.use_gae=False\n",
    "        self.gamma=.99\n",
    "        self.tau=.95\n",
    "        self.save_interval=1000\n",
    "        self.log_interval=100\n",
    "        self.from_saved=False\n",
    "        \n",
    "args = args()\n",
    "\n",
    "SAVE_PATH = \"saved_models/pong_112917.pt\"\n",
    "\n",
    "num_updates = int(args.num_frames) // args.num_steps // args.num_processes\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates 0, num timesteps 80, FPS 66, mean/median reward 0.0/0.0, min/max reward 0.0/0.0, entropy 1.58978, value loss 0.04211, policy loss 0.22921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-41:\n",
      "Process Process-34:\n",
      "Process Process-33:\n",
      "Process Process-47:\n",
      "Process Process-36:\n",
      "Process Process-43:\n",
      "Traceback (most recent call last):\n",
      "Process Process-38:\n",
      "Process Process-44:\n",
      "Process Process-39:\n",
      "Process Process-42:\n",
      "Process Process-46:\n",
      "Process Process-48:\n",
      "Process Process-35:\n",
      "Process Process-40:\n",
      "Traceback (most recent call last):\n",
      "Process Process-45:\n",
      "Traceback (most recent call last):\n",
      "Process Process-37:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/beans/pytorch-a2c-ppo-acktr/all_stuff.py\", line 8, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-13db7a3e9317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     next_value = actor_critic(Variable(rollouts.observations[-1], volatile=True),\n\u001b[0;32m---> 89\u001b[0;31m                               Variable(rollouts.masks[-1], volatile=True))[0].data\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mrollouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0a88c6248683>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "envs = [make_env(args.env_name, args.seed, i, args.log_dir) for i in range(args.num_processes)]\n",
    "\n",
    "if args.num_processes > 1:\n",
    "    envs = SubprocVecEnv(envs)\n",
    "else:\n",
    "    envs = DummyVecEnv(envs)\n",
    "\n",
    "if len(envs.observation_space.shape) == 1:\n",
    "    envs = VecNormalize(envs)\n",
    "\n",
    "obs_shape = envs.observation_space.shape\n",
    "obs_shape = (obs_shape[0] * args.num_stack, *obs_shape[1:])\n",
    "\n",
    "global actor_critic\n",
    "\n",
    "actor_critic = CNNPolicy(obs_shape[0], envs.action_space)\n",
    "\n",
    "if args.from_saved:\n",
    "    print(\"loading saved model from \" + SAVE_PATH)\n",
    "    actor_critic.load_state_dict(torch.load(SAVE_PATH))\n",
    "\n",
    "if envs.action_space.__class__.__name__ == \"Discrete\":\n",
    "    action_shape = 1\n",
    "else:\n",
    "    action_shape = envs.action_space.shape[0]\n",
    "\n",
    "if args.cuda:\n",
    "    actor_critic.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(actor_critic.parameters(), args.lr, eps=args.eps, alpha=args.alpha)\n",
    "\n",
    "rollouts = RolloutStorage(args.num_steps, args.num_processes, obs_shape, envs.action_space)\n",
    "current_obs = torch.zeros(args.num_processes, *obs_shape)\n",
    "\n",
    "def update_current_obs(obs):\n",
    "    shape_dim0 = envs.observation_space.shape[0]\n",
    "    obs = torch.from_numpy(obs).float()\n",
    "    if args.num_stack > 1:\n",
    "        current_obs[:, :-shape_dim0] = current_obs[:, shape_dim0:]\n",
    "    current_obs[:, -shape_dim0:] = obs\n",
    "\n",
    "obs = envs.reset()\n",
    "update_current_obs(obs)\n",
    "\n",
    "rollouts.observations[0].copy_(current_obs)\n",
    "\n",
    "# These variables are used to compute average rewards for all processes.\n",
    "episode_rewards = torch.zeros([args.num_processes, 1])\n",
    "final_rewards = torch.zeros([args.num_processes, 1])\n",
    "\n",
    "if args.cuda:\n",
    "    current_obs = current_obs.cuda()\n",
    "    rollouts.cuda()\n",
    "\n",
    "start = time.time()\n",
    "for j in range(num_updates):\n",
    "    for step in range(args.num_steps):\n",
    "        # Sample actions\n",
    "        value, action, action_log_prob = actor_critic.act(Variable(rollouts.observations[step], volatile=True),\n",
    "                                                                  Variable(rollouts.masks[step], volatile=True))\n",
    "        cpu_actions = action.data.squeeze(1).cpu().numpy()\n",
    "\n",
    "        # Obser reward and next obs\n",
    "        obs, reward, done, info = envs.step(cpu_actions)\n",
    "        reward = torch.from_numpy(np.expand_dims(np.stack(reward), 1)).float()\n",
    "        episode_rewards += reward\n",
    "\n",
    "        # If done then clean the history of observations.\n",
    "        masks = torch.FloatTensor([[0.0] if done_ else [1.0] for done_ in done])\n",
    "        final_rewards *= masks\n",
    "        final_rewards += (1 - masks) * episode_rewards\n",
    "        episode_rewards *= masks\n",
    "\n",
    "        if args.cuda:\n",
    "            masks = masks.cuda()\n",
    "\n",
    "        if current_obs.dim() == 4:\n",
    "            current_obs *= masks.unsqueeze(2).unsqueeze(2)\n",
    "        else:\n",
    "            current_obs *= masks\n",
    "\n",
    "        update_current_obs(obs)\n",
    "        rollouts.insert(step, current_obs, action.data, action_log_prob.data, value.data, reward, masks)\n",
    "\n",
    "    next_value = actor_critic(Variable(rollouts.observations[-1], volatile=True),\n",
    "                              Variable(rollouts.masks[-1], volatile=True))[0].data\n",
    "\n",
    "    rollouts.compute_returns(next_value, args.use_gae, args.gamma, args.tau)\n",
    "\n",
    "    values, action_log_probs, dist_entropy = actor_critic.evaluate_actions(Variable(rollouts.observations[:-1].view(-1, *obs_shape)),\n",
    "                                                                                   Variable(rollouts.masks[:-1].view(-1, 1)),\n",
    "                                                                                   Variable(rollouts.actions.view(-1, action_shape)))\n",
    "\n",
    "    values = values.view(args.num_steps, args.num_processes, 1)\n",
    "    action_log_probs = action_log_probs.view(args.num_steps, args.num_processes, 1)\n",
    "\n",
    "    advantages = Variable(rollouts.returns[:-1]) - values\n",
    "    value_loss = advantages.pow(2).mean()\n",
    "\n",
    "    action_loss = -(Variable(advantages.data) * action_log_probs).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    (value_loss * args.value_loss_coef + action_loss - dist_entropy * args.entropy_coef).backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm(actor_critic.parameters(), args.max_grad_norm)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    rollouts.after_update()\n",
    "\n",
    "    if j % args.save_interval == 0 and args.save_dir != \"\":\n",
    "\n",
    "        # A really ugly way to save a model to CPU\n",
    "        save_model = actor_critic\n",
    "        if args.cuda:\n",
    "            save_model = copy.deepcopy(actor_critic).cpu() # save THIS one\n",
    "\n",
    "        torch.save(save_model.state_dict(), SAVE_PATH)\n",
    "\n",
    "    if j % args.log_interval == 0:\n",
    "        end = time.time()\n",
    "        total_num_steps = (j + 1) * args.num_processes * args.num_steps\n",
    "        print(\"Updates {}, num timesteps {}, FPS {}, mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}, entropy {:.5f}, value loss {:.5f}, policy loss {:.5f}\".\n",
    "            format(j, total_num_steps,\n",
    "                   int(total_num_steps / (end - start)),\n",
    "                   final_rewards.mean(),\n",
    "                   final_rewards.median(),\n",
    "                   final_rewards.min(),\n",
    "                   final_rewards.max(), dist_entropy.data[0],\n",
    "                   value_loss.data[0], action_loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        orthogonal(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class CNNPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, action_space):\n",
    "        super(CNNPolicy, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_inputs, 32, 8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 32, 3, stride=1)\n",
    "\n",
    "        self.linear1 = nn.Linear(32 * 7 * 7, 512)\n",
    "\n",
    "        self.critic_linear = nn.Linear(512, 1)\n",
    "\n",
    "        if action_space.__class__.__name__ == \"Discrete\":\n",
    "            num_outputs = action_space.n\n",
    "            self.dist = Categorical(512, num_outputs)\n",
    "        elif action_space.__class__.__name__ == \"Box\":\n",
    "            num_outputs = action_space.shape[0]\n",
    "            self.dist = DiagGaussian(512, num_outputs)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.train()\n",
    "        self.reset_parameters()\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return 1\n",
    "\n",
    "    def act(self, inputs, masks, deterministic=False):\n",
    "        value, x = self(inputs, masks)\n",
    "        action = self.dist.sample(x, deterministic=deterministic)\n",
    "        action_log_probs, dist_entropy = self.dist.logprobs_and_entropy(x, action)\n",
    "        return value, action, action_log_probs\n",
    "\n",
    "    def evaluate_actions(self, inputs, masks, actions):\n",
    "        value, x = self(inputs, masks)\n",
    "        action_log_probs, dist_entropy = self.dist.logprobs_and_entropy(x, actions)\n",
    "        return value, action_log_probs, dist_entropy\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.apply(weights_init)\n",
    "\n",
    "        relu_gain = nn.init.calculate_gain('relu')\n",
    "        self.conv1.weight.data.mul_(relu_gain)\n",
    "        self.conv2.weight.data.mul_(relu_gain)\n",
    "        self.conv3.weight.data.mul_(relu_gain)\n",
    "        self.linear1.weight.data.mul_(relu_gain)\n",
    "\n",
    "        if self.dist.__class__.__name__ == \"DiagGaussian\":\n",
    "            self.dist.fc_mean.weight.data.mul_(0.01)\n",
    "\n",
    "    def forward(self, inputs, masks):\n",
    "        x = self.conv1(inputs / 255.0)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.critic_linear(x), x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutStorage(object):\n",
    "    def __init__(self, num_steps, num_processes, obs_shape, action_space):\n",
    "        self.observations = torch.zeros(num_steps + 1, num_processes, *obs_shape)\n",
    "        self.rewards = torch.zeros(num_steps, num_processes, 1)\n",
    "        self.value_preds = torch.zeros(num_steps + 1, num_processes, 1)\n",
    "        self.returns = torch.zeros(num_steps + 1, num_processes, 1)\n",
    "        self.action_log_probs = torch.zeros(num_steps, num_processes, 1)\n",
    "        if action_space.__class__.__name__ == 'Discrete':\n",
    "            action_shape = 1\n",
    "        else:\n",
    "            action_shape = action_space.shape[0]\n",
    "        self.actions = torch.zeros(num_steps, num_processes, action_shape)\n",
    "        if action_space.__class__.__name__ == 'Discrete':\n",
    "            self.actions = self.actions.long()\n",
    "        self.masks = torch.ones(num_steps + 1, num_processes, 1)\n",
    "\n",
    "    def cuda(self):\n",
    "        self.observations = self.observations.cuda()\n",
    "        self.rewards = self.rewards.cuda()\n",
    "        self.value_preds = self.value_preds.cuda()\n",
    "        self.returns = self.returns.cuda()\n",
    "        self.action_log_probs = self.action_log_probs.cuda()\n",
    "        self.actions = self.actions.cuda()\n",
    "        self.masks = self.masks.cuda()\n",
    "\n",
    "    def insert(self, step, current_obs, action, action_log_prob, value_pred, reward, mask):\n",
    "        self.observations[step + 1].copy_(current_obs)\n",
    "        self.actions[step].copy_(action)\n",
    "        self.action_log_probs[step].copy_(action_log_prob)\n",
    "        self.value_preds[step].copy_(value_pred)\n",
    "        self.rewards[step].copy_(reward)\n",
    "        self.masks[step + 1].copy_(mask)\n",
    "\n",
    "    def after_update(self):\n",
    "        self.observations[0].copy_(self.observations[-1])\n",
    "        self.masks[0].copy_(self.masks[-1])\n",
    "\n",
    "    def compute_returns(self, next_value, use_gae, gamma, tau):\n",
    "        if use_gae:\n",
    "            self.value_preds[-1] = next_value\n",
    "            gae = 0\n",
    "            for step in reversed(range(self.rewards.size(0))):\n",
    "                delta = self.rewards[step] + gamma * self.value_preds[step + 1] * self.masks[step + 1] - self.value_preds[step]\n",
    "                gae = delta + gamma * tau * self.masks[step + 1] * gae\n",
    "                self.returns[step] = gae + self.value_preds[step]\n",
    "        else:\n",
    "            self.returns[-1] = next_value\n",
    "            for step in reversed(range(self.rewards.size(0))):\n",
    "                self.returns[step] = self.returns[step + 1] * \\\n",
    "                    gamma * self.masks[step + 1] + self.rewards[step]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
